.

ğŸ§  Python Frameworks Assignment: CORD-19 Data Analysis & Streamlit App

Welcome to my Python Frameworks Assignment!
This repository showcases my work analyzing the CORD-19 research dataset, focusing on data exploration, visualization, and the creation of an interactive Streamlit web app for insight discovery.

ğŸ”— Live App: View on Streamlit Cloud https://nomize-frameworks-assignment-meta-cst38i.streamlit.app/

ğŸ“ GitHub Repository: Nomize/Frameworks_Assignment https://github.com/Nomize/Frameworks_Assignment

ğŸ“‚ Repository Structure
Frameworks_Assignment/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ metadata_sample.csv        # 2,000-row sample dataset for testing
â”œâ”€â”€ meta.py                        # Streamlit app code
â”œâ”€â”€ pyDA.py                        # Data processing script (used to create sample)
â”œâ”€â”€ pyDA.ipynb                     # Jupyter Notebook for initial exploration
â”œâ”€â”€ requirements.txt               # Project dependencies for Streamlit Cloud
â”œâ”€â”€ .gitignore                     # Ignores large files (metadata.csv, etc.)
â””â”€â”€ README.md                      # Project documentation
Note: The full metadata.csv (CORD-19) file is not included in the repo due to its large size (~2GB).
A smaller metadata_sample.csv file has been generated and is used for the Streamlit demo.

ğŸ§¾ 1ï¸âƒ£ Project Overview

This project explores the CORD-19 (COVID-19 Open Research Dataset) and demonstrates key data analysis and visualization techniques using Python frameworks.

Objectives

Load and explore real-world data

Clean and prepare large datasets efficiently

Visualize publication patterns and keyword trends

Build an interactive web app using Streamlit

ğŸ§¹ 2ï¸âƒ£ Data Loading & Cleaning
Steps Performed

Loaded a sample of 2,000 rows from the original dataset for performance efficiency

Cleaned missing values and standardized text columns

Converted publish_time to datetime format

Extracted publication year

Added a new column for abstract word counts

df["publish_time"] = pd.to_datetime(df["publish_time"], errors="coerce")
df["year"] = df["publish_time"].dt.year
df["abstract_word_count"] = df["abstract"].fillna("").apply(lambda x: len(x.split()))

ğŸ“Š 3ï¸âƒ£ Data Analysis & Visualization
Key Analyses

Publications over time â€” trends in COVID-19 research activity

Top publishing journals â€” top 10 journals by publication count

Word cloud of titles â€” most frequent words in paper titles

Abstract length distribution â€” histogram showing paper length trends

Libraries Used

pandas â†’ data cleaning & manipulation

matplotlib, seaborn â†’ data visualization

wordcloud â†’ keyword visualization

streamlit â†’ interactive web interface

ğŸ“ˆ Example Visualization:

Top 10 Journals Publishing COVID-19 Research (bar chart)

ğŸŒ 4ï¸âƒ£ Streamlit Application

The Streamlit app provides an interactive dashboard to explore the dataset dynamically.

App Features

âœ… Filter publications by year range
âœ… View dynamic visualizations (time trends, top journals, word clouds)
âœ… Explore sample data directly in the browser

Running Locally

Install dependencies:
pip install -r requirements.txt

Run the Streamlit app:
streamlit run meta.py
Or view it online here:
https://nomize-frameworks-assignment-meta-cst38i.streamlit.app/

Cloud

ğŸ’­ 5ï¸âƒ£ Challenges & Reflections
Challenges

Handling a large dataset (>1GB) that couldnâ€™t be easily loaded on limited RAM

Managing Git and Streamlit Cloud storage constraints

Optimizing for performance while maintaining analytical depth

What I Learned

Practical data cleaning and visualization workflows

Integrating Python notebooks with Streamlit for web-based analysis

Efficient handling of real-world data at scale

Deployment of machine learning/data apps on cloud platforms

ğŸ™Œ 6ï¸âƒ£ Credits

Dataset: CORD-19 (COVID-19 Open Research Dataset)

Frameworks: pandas, matplotlib, seaborn, wordcloud, streamlit

Created by: Nomize 

ğŸ§­ Final Notes

The app is fully deployed and functional on Streamlit Cloud.

You can clone this repository, replace the sample dataset with your own, and run the analysis locally.

The analysis output varies depending on the selected publication year range â€” wider year spans yield richer visualizations.
